{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark2_pracrice2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNcH4uAMRhEQAyRAS/Y6JFh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshaveenakondeti/pyspark/blob/main/pyspark2_pracrice2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a3Sa1CRNIvY",
        "outputId": "b6284153-246c-4a57-d44e-02dfb4f09a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 47 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 44.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=f5bcb72ab4e474ac9d068f2bdadba4c2de2e8aafe1aa4baf3053690fb960f1ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing pyspark\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "conf= SparkConf().setAppName('sec_class')\n",
        "sc=SparkContext(conf=conf)\n",
        "spark=SparkSession.builder.appName('Test').getOrCreate()\n",
        "sqlcontext=SQLContext(sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fI7iB33NQ2j",
        "outputId": "433f2e2e-b4a8-4188-d7d6-7816f212dfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:114: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import functions as f\n",
        "df = sc.parallelize([(\"James\", \"Sales\", 3000),\n",
        "(\"Michael\", \"Sales\", 4600),\n",
        "(\"Robert\", \"Sales\", 4100),\n",
        "(\"Maria\", \"Finance\", 3000),\n",
        "(\"James\", \"Sales\", 3000),\n",
        "(\"Scott\", \"Finance\", 3300),\n",
        "(\"Jen\", \"Finance\", 3900),\n",
        "(\"Jeff\", \"Marketing\", 3000),\n",
        "(\"Kumar\", \"Marketing\", 2000),\n",
        "(\"Saif\", \"Sales\", 4100)]).toDF([\"employee_name\",\"department\",'salary'])"
      ],
      "metadata": {
        "id": "EKr6WsHvNZLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res1 = df.groupBy('department').agg({'salary':'sum'})\n",
        "res1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eLptcZ5NxSe",
        "outputId": "16c8bdc8-63c9-40b8-f7ab-27bcc2b4486a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|department|sum(salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|      18800|\n",
            "|   Finance|      10200|\n",
            "| Marketing|       5000|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window  import Window\n",
        "from pyspark.sql.functions import col,avg,sum,min,max,row_number\n",
        "w=Window.partitionBy('department')\n",
        "df = df.withColumn('all_sum',sum(col('salary')).over(w))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MACZD68QOhb5",
        "outputId": "434f9483-8773-411b-f50b-c5ac68ea9b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+-------+-------+-------+\n",
            "|employee_name|department|salary|all_max|all_min|all_sum|\n",
            "+-------------+----------+------+-------+-------+-------+\n",
            "|        Maria|   Finance|  3000|   3900|   3000|  10200|\n",
            "|        Scott|   Finance|  3300|   3900|   3000|  10200|\n",
            "|          Jen|   Finance|  3900|   3900|   3000|  10200|\n",
            "|         Jeff| Marketing|  3000|   3000|   2000|   5000|\n",
            "|        Kumar| Marketing|  2000|   3000|   2000|   5000|\n",
            "|        James|     Sales|  3000|   4600|   3000|  18800|\n",
            "|      Michael|     Sales|  4600|   4600|   3000|  18800|\n",
            "|       Robert|     Sales|  4100|   4600|   3000|  18800|\n",
            "|        James|     Sales|  3000|   4600|   3000|  18800|\n",
            "|         Saif|     Sales|  4100|   4600|   3000|  18800|\n",
            "+-------------+----------+------+-------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# group by calculate overall, we will not get all columns\n",
        "# partition by , sum by row wise,rows are repeated"
      ],
      "metadata": {
        "id": "Fl1WaMZMPgJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max for al\n",
        "df = df.withColumn(\"all_max\",max(col('salary')).over(w))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmQ7iXwLQgP6",
        "outputId": "e3a61bf2-34ec-4574-e39f-99536844872a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+-------+\n",
            "|employee_name|department|salary|all_max|\n",
            "+-------------+----------+------+-------+\n",
            "|        Maria|   Finance|  3000|   3900|\n",
            "|        Scott|   Finance|  3300|   3900|\n",
            "|          Jen|   Finance|  3900|   3900|\n",
            "|         Jeff| Marketing|  3000|   3000|\n",
            "|        Kumar| Marketing|  2000|   3000|\n",
            "|        James|     Sales|  3000|   4600|\n",
            "|      Michael|     Sales|  4600|   4600|\n",
            "|       Robert|     Sales|  4100|   4600|\n",
            "|        James|     Sales|  3000|   4600|\n",
            "|         Saif|     Sales|  4100|   4600|\n",
            "+-------------+----------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"all_min\",min(col('salary')).over(w))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UMXNeCpQ6xz",
        "outputId": "86f64f6f-d5d7-4a3b-9896-32170d4b9126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+-------+-------+\n",
            "|employee_name|department|salary|all_max|all_min|\n",
            "+-------------+----------+------+-------+-------+\n",
            "|        Maria|   Finance|  3000|   3900|   3000|\n",
            "|        Scott|   Finance|  3300|   3900|   3000|\n",
            "|          Jen|   Finance|  3900|   3900|   3000|\n",
            "|         Jeff| Marketing|  3000|   3000|   2000|\n",
            "|        Kumar| Marketing|  2000|   3000|   2000|\n",
            "|        James|     Sales|  3000|   4600|   3000|\n",
            "|      Michael|     Sales|  4600|   4600|   3000|\n",
            "|       Robert|     Sales|  4100|   4600|   3000|\n",
            "|        James|     Sales|  3000|   4600|   3000|\n",
            "|         Saif|     Sales|  4100|   4600|   3000|\n",
            "+-------------+----------+------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"all_avg\",avg(col('salary')).over(w))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n2db9skRR7Q",
        "outputId": "5b9c31be-1e7c-40e7-dbe4-5248d4a25f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+-------+-------+-------+-------+\n",
            "|employee_name|department|salary|all_max|all_min|all_sum|all_avg|\n",
            "+-------------+----------+------+-------+-------+-------+-------+\n",
            "|        Maria|   Finance|  3000|   3900|   3000|  10200| 3400.0|\n",
            "|        Scott|   Finance|  3300|   3900|   3000|  10200| 3400.0|\n",
            "|          Jen|   Finance|  3900|   3900|   3000|  10200| 3400.0|\n",
            "|         Jeff| Marketing|  3000|   3000|   2000|   5000| 2500.0|\n",
            "|        Kumar| Marketing|  2000|   3000|   2000|   5000| 2500.0|\n",
            "|        James|     Sales|  3000|   4600|   3000|  18800| 3760.0|\n",
            "|      Michael|     Sales|  4600|   4600|   3000|  18800| 3760.0|\n",
            "|       Robert|     Sales|  4100|   4600|   3000|  18800| 3760.0|\n",
            "|        James|     Sales|  3000|   4600|   3000|  18800| 3760.0|\n",
            "|         Saif|     Sales|  4100|   4600|   3000|  18800| 3760.0|\n",
            "+-------------+----------+------+-------+-------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it is window function used to give the seuential row number startting fr\n",
        "# row number means, for each department, based on order it is assigning number\n",
        "from pyspark.sql.functions import row_number\n",
        "windowSpec = Window.partitionBy('department').orderBy('Salary')\n",
        "res = df.withColumn(\"row_number\",row_number().over(windowSpec))\n",
        "res.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y9VJH4mRF-t",
        "outputId": "36cf302a-4657-46f8-9167-c58fa2977a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+-------+-------+-------+-------+----------+\n",
            "|employee_name|department|salary|all_max|all_min|all_sum|all_avg|row_number|\n",
            "+-------------+----------+------+-------+-------+-------+-------+----------+\n",
            "|        Maria|   Finance|  3000|   3900|   3000|  10200| 3400.0|         1|\n",
            "|        Scott|   Finance|  3300|   3900|   3000|  10200| 3400.0|         2|\n",
            "|          Jen|   Finance|  3900|   3900|   3000|  10200| 3400.0|         3|\n",
            "|        Kumar| Marketing|  2000|   3000|   2000|   5000| 2500.0|         1|\n",
            "|         Jeff| Marketing|  3000|   3000|   2000|   5000| 2500.0|         2|\n",
            "|        James|     Sales|  3000|   4600|   3000|  18800| 3760.0|         1|\n",
            "|        James|     Sales|  3000|   4600|   3000|  18800| 3760.0|         2|\n",
            "|       Robert|     Sales|  4100|   4600|   3000|  18800| 3760.0|         3|\n",
            "|         Saif|     Sales|  4100|   4600|   3000|  18800| 3760.0|         4|\n",
            "|      Michael|     Sales|  4600|   4600|   3000|  18800| 3760.0|         5|\n",
            "+-------------+----------+------+-------+-------+-------+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rank()\n",
        "from pyspark.sql.functions import rank\n",
        "res1 = df.withColumn('rank',rank().over(windowSpec))\n",
        "res1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ5N_VS_TeMm",
        "outputId": "847c8d49-1b85-4203-8d0f-a686e7588bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+-------+-------+-------+-------+----+\n",
            "|employee_name|department|salary|all_max|all_min|all_sum|all_avg|rank|\n",
            "+-------------+----------+------+-------+-------+-------+-------+----+\n",
            "|        Maria|   Finance|  3000|   3900|   3000|  10200| 3400.0|   1|\n",
            "|        Scott|   Finance|  3300|   3900|   3000|  10200| 3400.0|   2|\n",
            "|          Jen|   Finance|  3900|   3900|   3000|  10200| 3400.0|   3|\n",
            "|        Kumar| Marketing|  2000|   3000|   2000|   5000| 2500.0|   1|\n",
            "|         Jeff| Marketing|  3000|   3000|   2000|   5000| 2500.0|   2|\n",
            "|        James|     Sales|  3000|   4600|   3000|  18800| 3760.0|   1|\n",
            "|        James|     Sales|  3000|   4600|   3000|  18800| 3760.0|   1|\n",
            "|       Robert|     Sales|  4100|   4600|   3000|  18800| 3760.0|   3|\n",
            "|         Saif|     Sales|  4100|   4600|   3000|  18800| 3760.0|   3|\n",
            "|      Michael|     Sales|  4600|   4600|   3000|  18800| 3760.0|   5|\n",
            "+-------------+----------+------+-------+-------+-------+-------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rank will skip 1 rank for duplicates, but internally it has counted\n",
        "# it will leaves gaps when there ties\n",
        "# it provides a rank to the result within a window partition\n"
      ],
      "metadata": {
        "id": "G5p300LAVgot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import dense_rank\n",
        "res3 =df.withColumn('dense_rank',dense_rank().over(windowSpec))\n",
        "res3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BEaTZueWknc",
        "outputId": "17375e5f-7ad7-44ec-8b7f-cc71021a5d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+-------+-------+-------+-------+----------+\n",
            "|employee_name|department|salary|all_max|all_min|all_sum|all_avg|dense_rank|\n",
            "+-------------+----------+------+-------+-------+-------+-------+----------+\n",
            "|        Maria|   Finance|  3000|   3900|   3000|  10200| 3400.0|         1|\n",
            "|        Scott|   Finance|  3300|   3900|   3000|  10200| 3400.0|         2|\n",
            "|          Jen|   Finance|  3900|   3900|   3000|  10200| 3400.0|         3|\n",
            "|        Kumar| Marketing|  2000|   3000|   2000|   5000| 2500.0|         1|\n",
            "|         Jeff| Marketing|  3000|   3000|   2000|   5000| 2500.0|         2|\n",
            "|        James|     Sales|  3000|   4600|   3000|  18800| 3760.0|         1|\n",
            "|        James|     Sales|  3000|   4600|   3000|  18800| 3760.0|         1|\n",
            "|       Robert|     Sales|  4100|   4600|   3000|  18800| 3760.0|         2|\n",
            "|         Saif|     Sales|  4100|   4600|   3000|  18800| 3760.0|         2|\n",
            "|      Michael|     Sales|  4600|   4600|   3000|  18800| 3760.0|         3|\n",
            "+-------------+----------+------+-------+-------+-------+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "rank count internally, dense rank doesnot count internally. it will not show gaps.\n",
        "dense_rank() window function is used to get the result without any gaps."
      ],
      "metadata": {
        "id": "zMn_h5_dXL95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lag\n",
        "df.withColumn(\"lag\",lag(\"salary\",1).over(windowSpec)).show() # top to bottom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKUHvVa_Wkjw",
        "outputId": "8ea60580-50ee-462c-e644-98bb410443f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+-------+-------+-------+-------+----+\n",
            "|employee_name|department|salary|all_max|all_min|all_sum|all_avg| lag|\n",
            "+-------------+----------+------+-------+-------+-------+-------+----+\n",
            "|        Maria|   Finance|  3000|   3900|   3000|  10200| 3400.0|null|\n",
            "|        Scott|   Finance|  3300|   3900|   3000|  10200| 3400.0|3000|\n",
            "|          Jen|   Finance|  3900|   3900|   3000|  10200| 3400.0|3300|\n",
            "|        Kumar| Marketing|  2000|   3000|   2000|   5000| 2500.0|null|\n",
            "|         Jeff| Marketing|  3000|   3000|   2000|   5000| 2500.0|2000|\n",
            "|        James|     Sales|  3000|   4600|   3000|  18800| 3760.0|null|\n",
            "|        James|     Sales|  3000|   4600|   3000|  18800| 3760.0|3000|\n",
            "|       Robert|     Sales|  4100|   4600|   3000|  18800| 3760.0|3000|\n",
            "|         Saif|     Sales|  4100|   4600|   3000|  18800| 3760.0|4100|\n",
            "|      Michael|     Sales|  4600|   4600|   3000|  18800| 3760.0|4100|\n",
            "+-------------+----------+------+-------+-------+-------+-------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lead\n",
        "df.withColumn(\"lead\",lead(\"salary\",1).over(windowSpec)).show() # bottom to top"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyuVARuoWkd9",
        "outputId": "1d48606e-ebf7-4cc6-977a-01282f5f1578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----+\n",
            "|employee_name|department|salary|lead|\n",
            "+-------------+----------+------+----+\n",
            "|        Maria|   Finance|  3000|3300|\n",
            "|        Scott|   Finance|  3300|3900|\n",
            "|          Jen|   Finance|  3900|null|\n",
            "|        Kumar| Marketing|  2000|3000|\n",
            "|         Jeff| Marketing|  3000|null|\n",
            "|        James|     Sales|  3000|3000|\n",
            "|        James|     Sales|  3000|4100|\n",
            "|       Robert|     Sales|  4100|4100|\n",
            "|         Saif|     Sales|  4100|4600|\n",
            "|      Michael|     Sales|  4600|null|\n",
            "+-------------+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as f\n",
        "df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"/content/Test_Date2.csv\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thPkttaCWkaf",
        "outputId": "7a7b14f7-2ec9-45b3-a88d-e9cda2466409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------+---+\n",
            "|      Date| id|Volume|Age|\n",
            "+----------+---+------+---+\n",
            "|08/26/2016|100|  90.7| 26|\n",
            "|08/27/2016|101|  90.7| 26|\n",
            "|08/26/2016|102|  90.7| 26|\n",
            "|06/14/2016|103|  90.7| 26|\n",
            "|06/19/2016|102|  90.7| 26|\n",
            "|06/25/2016|104|  90.5| 27|\n",
            "+----------+---+------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0zNVNDBWkXz",
        "outputId": "094744b8-0672-43af-ea9c-150555df08c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- id: integer (nullable = true)\n",
            " |-- Volume: double (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.printSchema()\n",
        "modifiedDF = df.withColumn(\"Date\", f.to_date(df.Date, \"MM/dd/yyyy\"))\n",
        "modifiedDF = modifiedDF.withColumn(\"birth_year\",f.year(modifiedDF.Date))\n",
        "modifiedDF = modifiedDF.withColumn(\"birth_month\",f.month(modifiedDF.Date))\n",
        "modifiedDF = modifiedDF.withColumn(\"birth_date\",f.dayofmonth(modifiedDF.Date))\n",
        "modifiedDF = modifiedDF.withColumn(\"fivteen_days_later\",f.date_add(modifiedDF.Date, 15))\n",
        "modifiedDF = modifiedDF.withColumn(\"twentty_days_Before\",f.date_add(modifiedDF.Date, -20))\n",
        "#modifiedDF.show()\n",
        "modifiedDF.show()\n",
        "#modifiedDF.printSchema()\n",
        "#modifiedDF.show()"
      ],
      "metadata": {
        "id": "hrrxGyk8WkVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.withColumn('Date',f.to_date(df.Date,\"MM/dd/yyyy\"))\n",
        "df1.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJkxz0Ulas_c",
        "outputId": "bb587fdb-630d-4f01-a708-4a45cf732a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: date (nullable = true)\n",
            " |-- id: integer (nullable = true)\n",
            " |-- Volume: double (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1.withColumn('birth_year',f.year(df1.Date))\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkUFrWWtbLPu",
        "outputId": "e190889b-7142-44e0-a546-065e21cc0d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------+---+----------+\n",
            "|      Date| id|Volume|Age|birth_year|\n",
            "+----------+---+------+---+----------+\n",
            "|2016-08-26|100|  90.7| 26|      2016|\n",
            "|2016-08-27|101|  90.7| 26|      2016|\n",
            "|2016-08-26|102|  90.7| 26|      2016|\n",
            "|2016-06-14|103|  90.7| 26|      2016|\n",
            "|2016-06-19|102|  90.7| 26|      2016|\n",
            "|2016-06-25|104|  90.5| 27|      2016|\n",
            "+----------+---+------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1.withColumn('get_month',f.month(df1.Date))\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrF8SzK6bfwJ",
        "outputId": "80ba29c2-aa12-414c-ad15-96f730eb76c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------+---+----------+---------+\n",
            "|      Date| id|Volume|Age|birth_year|get_month|\n",
            "+----------+---+------+---+----------+---------+\n",
            "|2016-08-26|100|  90.7| 26|      2016|        8|\n",
            "|2016-08-27|101|  90.7| 26|      2016|        8|\n",
            "|2016-08-26|102|  90.7| 26|      2016|        8|\n",
            "|2016-06-14|103|  90.7| 26|      2016|        6|\n",
            "|2016-06-19|102|  90.7| 26|      2016|        6|\n",
            "|2016-06-25|104|  90.5| 27|      2016|        6|\n",
            "+----------+---+------+---+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 =df1.withColumn('get_date',f.dayofmonth(col(\"Date\")))\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X3PE8EucB7C",
        "outputId": "2ce72dec-31a4-42aa-e2a3-d96c2b1a71ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------+---+----------+---------+--------+\n",
            "|      Date| id|Volume|Age|birth_year|get_month|get_date|\n",
            "+----------+---+------+---+----------+---------+--------+\n",
            "|2016-08-26|100|  90.7| 26|      2016|        8|      26|\n",
            "|2016-08-27|101|  90.7| 26|      2016|        8|      27|\n",
            "|2016-08-26|102|  90.7| 26|      2016|        8|      26|\n",
            "|2016-06-14|103|  90.7| 26|      2016|        6|      14|\n",
            "|2016-06-19|102|  90.7| 26|      2016|        6|      19|\n",
            "|2016-06-25|104|  90.5| 27|      2016|        6|      25|\n",
            "+----------+---+------+---+----------+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 =df1.withColumn(\"15 days later\",f.date_add(col(\"Date\"),15))\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa76YYcLcVbe",
        "outputId": "6622cd52-dee5-40c2-ea9c-c371a7c88056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------+---+----------+---------+--------+-------------+\n",
            "|      Date| id|Volume|Age|birth_year|get_month|get_date|15 days later|\n",
            "+----------+---+------+---+----------+---------+--------+-------------+\n",
            "|2016-08-26|100|  90.7| 26|      2016|        8|      26|   2016-09-10|\n",
            "|2016-08-27|101|  90.7| 26|      2016|        8|      27|   2016-09-11|\n",
            "|2016-08-26|102|  90.7| 26|      2016|        8|      26|   2016-09-10|\n",
            "|2016-06-14|103|  90.7| 26|      2016|        6|      14|   2016-06-29|\n",
            "|2016-06-19|102|  90.7| 26|      2016|        6|      19|   2016-07-04|\n",
            "|2016-06-25|104|  90.5| 27|      2016|        6|      25|   2016-07-10|\n",
            "+----------+---+------+---+----------+---------+--------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 =df1.withColumn(\"22 days back\",f.date_sub(col(\"Date\"),22))\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1PkALz0eR6U",
        "outputId": "8caf5e79-6740-4bca-976c-a5b497557c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------+---+----------+---------+--------+-------------+------------+----+------------+\n",
            "|      Date| id|Volume|Age|birth_year|get_month|get_date|15 days later|20 days back|week|22 days back|\n",
            "+----------+---+------+---+----------+---------+--------+-------------+------------+----+------------+\n",
            "|2016-08-26|100|  90.7| 26|      2016|        8|      26|   2016-09-10|  2016-08-06|  34|  2016-08-04|\n",
            "|2016-08-27|101|  90.7| 26|      2016|        8|      27|   2016-09-11|  2016-08-07|  34|  2016-08-05|\n",
            "|2016-08-26|102|  90.7| 26|      2016|        8|      26|   2016-09-10|  2016-08-06|  34|  2016-08-04|\n",
            "|2016-06-14|103|  90.7| 26|      2016|        6|      14|   2016-06-29|  2016-05-25|  24|  2016-05-23|\n",
            "|2016-06-19|102|  90.7| 26|      2016|        6|      19|   2016-07-04|  2016-05-30|  24|  2016-05-28|\n",
            "|2016-06-25|104|  90.5| 27|      2016|        6|      25|   2016-07-10|  2016-06-05|  25|  2016-06-03|\n",
            "+----------+---+------+---+----------+---------+--------+-------------+------------+----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 =df1.withColumn(\"20 days back\",f.date_add(col(\"Date\"),-20))\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jVsQ2OCc-Nj",
        "outputId": "7da38102-c027-44d4-a151-37e56c26c728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------+---+----------+---------+--------+-------------+------------+\n",
            "|      Date| id|Volume|Age|birth_year|get_month|get_date|15 days later|20 days back|\n",
            "+----------+---+------+---+----------+---------+--------+-------------+------------+\n",
            "|2016-08-26|100|  90.7| 26|      2016|        8|      26|   2016-09-10|  2016-08-06|\n",
            "|2016-08-27|101|  90.7| 26|      2016|        8|      27|   2016-09-11|  2016-08-07|\n",
            "|2016-08-26|102|  90.7| 26|      2016|        8|      26|   2016-09-10|  2016-08-06|\n",
            "|2016-06-14|103|  90.7| 26|      2016|        6|      14|   2016-06-29|  2016-05-25|\n",
            "|2016-06-19|102|  90.7| 26|      2016|        6|      19|   2016-07-04|  2016-05-30|\n",
            "|2016-06-25|104|  90.5| 27|      2016|        6|      25|   2016-07-10|  2016-06-05|\n",
            "+----------+---+------+---+----------+---------+--------+-------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 =df1.withColumn('week',f.weekofyear(col(\"Date\")))\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOnbWXk4dThm",
        "outputId": "7fa82e18-2988-4e39-e653-e0d4b7a4e85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------+---+----------+---------+--------+-------------+------------+----+\n",
            "|      Date| id|Volume|Age|birth_year|get_month|get_date|15 days later|20 days back|week|\n",
            "+----------+---+------+---+----------+---------+--------+-------------+------------+----+\n",
            "|2016-08-26|100|  90.7| 26|      2016|        8|      26|   2016-09-10|  2016-08-06|  34|\n",
            "|2016-08-27|101|  90.7| 26|      2016|        8|      27|   2016-09-11|  2016-08-07|  34|\n",
            "|2016-08-26|102|  90.7| 26|      2016|        8|      26|   2016-09-10|  2016-08-06|  34|\n",
            "|2016-06-14|103|  90.7| 26|      2016|        6|      14|   2016-06-29|  2016-05-25|  24|\n",
            "|2016-06-19|102|  90.7| 26|      2016|        6|      19|   2016-07-04|  2016-05-30|  24|\n",
            "|2016-06-25|104|  90.5| 27|      2016|        6|      25|   2016-07-10|  2016-06-05|  25|\n",
            "+----------+---+------+---+----------+---------+--------+-------------+------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= spark.read.format(\"csv\").option('header','true').option('inferschema','true').load('/content/Test_TimeStamp.csv')"
      ],
      "metadata": {
        "id": "N_wUiGudd6nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrw6hb7Ae3cS",
        "outputId": "0f16e2f7-988a-4851-b5d2-ff7d49d6d763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- DateTime: timestamp (nullable = true)\n",
            " |-- id: double (nullable = true)\n",
            " |-- Volume: double (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('minute',f.minute(col(\"DateTime\")))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLscMmJmfDl5",
        "outputId": "4be26a83-7b21-44e2-db44-d545efc7e523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+------+----+------+\n",
            "|           DateTime|   id|Volume| Age|minute|\n",
            "+-------------------+-----+------+----+------+\n",
            "|2017-08-02 03:04:00|100.0|  90.7|  26|     4|\n",
            "|1999-07-05 01:45:20| 90.7|  26.0|null|    45|\n",
            "|1998-08-06 01:35:20|102.0|  90.7|  26|    35|\n",
            "|1997-09-07 01:25:19|103.0|  90.7|  26|    25|\n",
            "|1996-03-03 01:15:18|102.0|  90.7|  26|    15|\n",
            "|1995-09-05 01:05:17|104.0|  90.5|  27|     5|\n",
            "+-------------------+-----+------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('second',f.second(col(\"DateTime\")))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYiYErYIfUuL",
        "outputId": "aebc8024-fa9c-4081-e6b1-293c3b7a44ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+------+----+------+------+\n",
            "|           DateTime|   id|Volume| Age|minute|second|\n",
            "+-------------------+-----+------+----+------+------+\n",
            "|2017-08-02 03:04:00|100.0|  90.7|  26|     4|     0|\n",
            "|1999-07-05 01:45:20| 90.7|  26.0|null|    45|    20|\n",
            "|1998-08-06 01:35:20|102.0|  90.7|  26|    35|    20|\n",
            "|1997-09-07 01:25:19|103.0|  90.7|  26|    25|    19|\n",
            "|1996-03-03 01:15:18|102.0|  90.7|  26|    15|    18|\n",
            "|1995-09-05 01:05:17|104.0|  90.5|  27|     5|    17|\n",
            "+-------------------+-----+------+----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('Quarter',f.quarter(col(\"DateTime\")))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_6jXLNXfhZE",
        "outputId": "aca309e2-eee7-415e-eda8-0c4e200b469b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+------+----+------+------+-------+\n",
            "|           DateTime|   id|Volume| Age|minute|second|Quarter|\n",
            "+-------------------+-----+------+----+------+------+-------+\n",
            "|2017-08-02 03:04:00|100.0|  90.7|  26|     4|     0|      3|\n",
            "|1999-07-05 01:45:20| 90.7|  26.0|null|    45|    20|      3|\n",
            "|1998-08-06 01:35:20|102.0|  90.7|  26|    35|    20|      3|\n",
            "|1997-09-07 01:25:19|103.0|  90.7|  26|    25|    19|      3|\n",
            "|1996-03-03 01:15:18|102.0|  90.7|  26|    15|    18|      1|\n",
            "|1995-09-05 01:05:17|104.0|  90.5|  27|     5|    17|      3|\n",
            "+-------------------+-----+------+----+------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('hour',f.hour(col(\"DateTime\")))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7UKBhh_fx7C",
        "outputId": "f4b1c14a-8300-47b6-a77b-2b60f73ee2f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+------+----+------+------+-------+----+\n",
            "|           DateTime|   id|Volume| Age|minute|second|Quarter|hour|\n",
            "+-------------------+-----+------+----+------+------+-------+----+\n",
            "|2017-08-02 03:04:00|100.0|  90.7|  26|     4|     0|      3|   3|\n",
            "|1999-07-05 01:45:20| 90.7|  26.0|null|    45|    20|      3|   1|\n",
            "|1998-08-06 01:35:20|102.0|  90.7|  26|    35|    20|      3|   1|\n",
            "|1997-09-07 01:25:19|103.0|  90.7|  26|    25|    19|      3|   1|\n",
            "|1996-03-03 01:15:18|102.0|  90.7|  26|    15|    18|      1|   1|\n",
            "|1995-09-05 01:05:17|104.0|  90.5|  27|     5|    17|      3|   1|\n",
            "+-------------------+-----+------+----+------+------+-------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('hours',f.hours(col(\"DateTime\")))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DL_AW773f6kn",
        "outputId": "9e96ae75-2cbf-4188-bf4b-bf5034f1f3dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-85e81efe0f45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hours'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DateTime\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o291.showString.\n: org.apache.spark.SparkUnsupportedOperationException: Cannot generate code for expression: hours(input[0, timestamp, true])\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.cannotGenerateCodeForExpressionError(QueryExecutionErrors.scala:78)\n\tat org.apache.spark.sql.catalyst.expressions.Unevaluable.doGenCode(Expression.scala:347)\n\tat org.apache.spark.sql.catalyst.expressions.Unevaluable.doGenCode$(Expression.scala:346)\n\tat org.apache.spark.sql.catalyst.expressions.PartitionTransformExpression.doGenCode(PartitionTransforms.scala:36)\n\tat org.apache.spark.sql.catalyst.expressions.Expression.$anonfun$genCode$3(Expression.scala:151)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.catalyst.expressions.Expression.genCode(Expression.scala:146)\n\tat org.apache.spark.sql.catalyst.expressions.CastBase.doGenCode(Cast.scala:1004)\n\tat org.apache.spark.sql.catalyst.expressions.Expression.$anonfun$genCode$3(Expression.scala:151)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.catalyst.expressions.Expression.genCode(Expression.scala:146)\n\tat org.apache.spark.sql.catalyst.expressions.CastBase.genCode(Cast.scala:995)\n\tat org.apache.spark.sql.catalyst.expressions.Alias.genCode(namedExpressions.scala:161)\n\tat org.apache.spark.sql.execution.ProjectExec.$anonfun$doConsume$2(basicPhysicalOperators.scala:74)\n\tat scala.collection.immutable.List.map(List.scala:297)\n\tat org.apache.spark.sql.execution.ProjectExec.$anonfun$doConsume$1(basicPhysicalOperators.scala:74)\n\tat org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.withSubExprEliminationExprs(CodeGenerator.scala:1040)\n\tat org.apache.spark.sql.execution.ProjectExec.doConsume(basicPhysicalOperators.scala:74)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:196)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:151)\n\tat org.apache.spark.sql.execution.InputAdapter.consume(WholeStageCodegenExec.scala:498)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.doProduce(WholeStageCodegenExec.scala:485)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.doProduce$(WholeStageCodegenExec.scala:458)\n\tat org.apache.spark.sql.execution.InputAdapter.doProduce(WholeStageCodegenExec.scala:498)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:97)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:232)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:229)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:92)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:92)\n\tat org.apache.spark.sql.execution.InputAdapter.produce(WholeStageCodegenExec.scala:498)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:55)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:97)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:232)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:229)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:92)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:92)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:42)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:660)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:723)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:194)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:232)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:229)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:190)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:340)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:473)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:459)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2863)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2863)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3084)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:288)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:327)\n\tat jdk.internal.reflect.GeneratedMethodAccessor59.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"header\",\"true\").option('inferschema','true').json(\"/content/first.json\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70moXeLSgK1c",
        "outputId": "4affa936-974d-4a13-cec4-5be41b2e3444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-------+\n",
            "|age|  id|   name|\n",
            "+---+----+-------+\n",
            "| 25|1201| satish|\n",
            "| 28|1202|krishna|\n",
            "| 39|1203|  amith|\n",
            "| 23|1204|  javed|\n",
            "| 23|1205| prudvi|\n",
            "+---+----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfJnA07bqSTu",
        "outputId": "ce49cd91-6e3b-44e9-ed33-f0bee105ce69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"header\",\"true\").option('inferschema','true').option(\"multiline\",'true').json(\"/content/test_multiLine.json\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1NBJWSYq0Ja",
        "outputId": "ba8acb1e-e228-4a61-bbe9-9f39997cd4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+------+\n",
            "|age| id|  name|\n",
            "+---+---+------+\n",
            "| 21|  1|aakash|\n",
            "+---+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set : any collection of element\n",
        "# f.collect_list : collect list of rows\n",
        "# f.collect.set9\n",
        "\n",
        "\n",
        "df.show()\n",
        "df.groupBy(\"department\").agg(f.collect_list(\"salary\"),f.collect_set(\"salary\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPY2I5OFrP93",
        "outputId": "0d295faf-60fe-41b8-fa55-93e5e230803a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|        James|     Sales|  3000|\n",
            "|      Michael|     Sales|  4600|\n",
            "|       Robert|     Sales|  4100|\n",
            "|        Maria|   Finance|  3000|\n",
            "|        James|     Sales|  3000|\n",
            "|        Scott|   Finance|  3300|\n",
            "|          Jen|   Finance|  3900|\n",
            "|         Jeff| Marketing|  3000|\n",
            "|        Kumar| Marketing|  2000|\n",
            "|         Saif|     Sales|  4100|\n",
            "+-------------+----------+------+\n",
            "\n",
            "+----------+------------------------------+-------------------+\n",
            "|department|collect_list(salary)          |collect_set(salary)|\n",
            "+----------+------------------------------+-------------------+\n",
            "|Sales     |[3000, 4600, 4100, 3000, 4100]|[4600, 3000, 4100] |\n",
            "|Finance   |[3000, 3300, 3900]            |[3900, 3000, 3300] |\n",
            "|Marketing |[3000, 2000]                  |[3000, 2000]       |\n",
            "+----------+------------------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lCnHISuCubl3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}